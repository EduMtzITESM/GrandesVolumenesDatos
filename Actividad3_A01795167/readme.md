# Grandes Vol煤menes de datos

+ Estudiante: Eduardo Selim Mart铆nez Mayorga

# Actividad 3: Aprendizaje supervisado y no supervisado

# Parte 1: Introducci贸n te贸rica

## Machine Learning

**Aprendizaje Supervisado**: Este tipo de aprendizaje utiliza conjuntos de datos etiquetados donde cada ejemplo de entrada tiene una salida conocida y correcta. El algoritmo aprende a mapear las entradas a las salidas correctas mediante la observaci贸n de estos pares entrada-salida durante el entrenamiento. Su objetivo principal es construir un modelo que pueda predecir con precisi贸n las etiquetas o valores de nuevos datos no vistos anteriormente. Se divide en dos categor铆as: clasificaci贸n (predecir categor铆as discretas como spam/no spam) y regresi贸n (predecir valores continuos como precios de casas).

**Aprendizaje No Supervisado**: En este enfoque, el algoritmo trabaja con datos que no tienen etiquetas o respuestas conocidas, debiendo descubrir patrones ocultos y estructuras en los datos por s铆 mismo. El objetivo es encontrar representaciones 煤tiles de los datos, agrupar elementos similares, reducir dimensionalidad o detectar anomal铆as sin guidance externa. Las t茅cnicas m谩s comunes incluyen clustering (agrupamiento), reducci贸n de dimensionalidad, y detecci贸n de patrones, siendo especialmente valioso para explorar datos desconocidos y encontrar insights que no son evidentes a simple vista.

**Aprendizaje Semi-supervisado**: Esta metodolog铆a combina elementos del aprendizaje supervisado y no supervisado, utilizando una peque帽a cantidad de datos etiquetados junto con una gran cantidad de datos sin etiquetar. El objetivo es aprovechar la abundante informaci贸n no etiquetada para mejorar el rendimiento del modelo m谩s all谩 de lo que ser铆a posible usando solo los limitados datos etiquetados. Es particularmente 煤til cuando obtener etiquetas es costoso o requiere mucho tiempo, como en reconocimiento de im谩genes m茅dicas o procesamiento de lenguaje natural, donde se puede usar texto abundante sin anotar para mejorar modelos entrenados con pocos ejemplos etiquetados.

**Aprendizaje por refuerzo**: En este paradigma, un agente aprende a tomar decisiones 贸ptimas en un entorno mediante la interacci贸n directa, recibiendo recompensas o castigos basados en sus acciones. El objetivo es que el agente desarrolle una pol铆tica de comportamiento que maximice la recompensa acumulada a largo plazo, aprendiendo qu茅 acciones tomar en diferentes situaciones a trav茅s de prueba y error. No requiere ejemplos etiquetados, sino que aprende de las consecuencias de sus propias acciones, siendo fundamental en aplicaciones como juegos, rob贸tica, sistemas de recomendaci贸n y control aut贸nomo, donde el agente debe aprender estrategias 贸ptimas para alcanzar objetivos espec铆ficos.

En PySpark (la API de Python para Apache Spark), el m贸dulo `pyspark.ml` proporciona varios **algoritmos de aprendizaje supervisado**, tanto para **clasificaci贸n** como para **regresi贸n**. Aqu铆 tienes un resumen de los principales:

###  CLASIFICACIN (`pyspark.ml.classification`)

1. **Logistic Regression**
   `LogisticRegression()`
   Ideal para clasificaci贸n binaria y multiclase (mediante softmax).

2. **Decision Tree Classifier**
   `DecisionTreeClassifier()`
   rbol de decisi贸n para clasificaci贸n.

3. **Random Forest Classifier**
   `RandomForestClassifier()`
   Ensamble de 谩rboles; mejora precisi贸n y reduce overfitting.

4. **Gradient-Boosted Tree (GBT) Classifier**
   `GBTClassifier()`
   Variante de boosting sobre 谩rboles; muy potente para clasificaci贸n binaria.

5. **Naive Bayes**
   `NaiveBayes()`
   Modelo probabil铆stico, 煤til con texto y datos categ贸ricos.

6. **Multilayer Perceptron Classifier**
   `MultilayerPerceptronClassifier()`
   Red neuronal multicapa; 煤til para clasificaci贸n no lineal.

7. **Linear Support Vector Machine (SVM)**
   `LinearSVC()`
   SVM para clasificaci贸n binaria (con margen suave).

---

###  REGRESIN (`pyspark.ml.regression`)

1. **Linear Regression**
   `LinearRegression()`
   Modelo lineal cl谩sico.

2. **Generalized Linear Regression (GLR)**
   `GeneralizedLinearRegression()`
   Ampliaci贸n del modelo lineal para diferentes distribuciones (Poisson, Gamma, etc.).

3. **Decision Tree Regressor**
   `DecisionTreeRegressor()`
   rbol de decisi贸n para regresi贸n.

4. **Random Forest Regressor**
   `RandomForestRegressor()`
   Ensamble de 谩rboles para regresi贸n.

5. **Gradient-Boosted Tree Regressor**
   `GBTRegressor()`
   Boosting sobre 谩rboles para regresi贸n.

6. **Isotonic Regression**
   `IsotonicRegression()`
   Regresi贸n no param茅trica, 煤til cuando se asume una relaci贸n mon贸tonamente creciente o decreciente.


### Otros Componentes Importantes

* **Pipelines y Transformers** para preprocesamiento: `VectorAssembler`, `StringIndexer`, `StandardScaler`, etc.
* **Evaluadores**: `BinaryClassificationEvaluator`, `MulticlassClassificationEvaluator`, `RegressionEvaluator`.

---

En **PySpark**, los algoritmos de **aprendizaje no supervisado** est谩n disponibles principalmente en el m贸dulo `pyspark.ml.clustering` (para *clustering*) y `pyspark.ml.fpm` (para *pattern mining*). A continuaci贸n te presento los principales algoritmos no supervisados que puedes usar:

---

###  ALGORITMOS DE CLUSTERING (`pyspark.ml.clustering`)

1. **K-Means**
   `KMeans()`
   Clustering basado en centros de masa. Requiere especificar el n煤mero de clusters `k`.

2. **Bisecting K-Means**
   `BisectingKMeans()`
   Variante jer谩rquica de K-Means, 煤til para estructuras de cluster en 谩rbol.

3. **Gaussian Mixture Model (GMM)**
   `GaussianMixture()`
   Modelo probabil铆stico que asume que los datos provienen de una mezcla de distribuciones normales. Devuelve probabilidades de pertenencia.

4. **Latent Dirichlet Allocation (LDA)**
   `LDA()`
   Modelo probabil铆stico para an谩lisis de t贸picos en texto. Agrupa documentos por temas latentes.

5. **Power Iteration Clustering (PIC)**
   `PowerIterationClustering()`
   Algoritmo de clustering espectral escalable, basado en el an谩lisis del grafo de similitud entre elementos.

---

###  ALGORITMOS DE MINERA DE PATRONES FRECUENTES (`pyspark.ml.fpm`)

6. **Frequent Pattern Growth (FP-Growth)**
   `FPGrowth()`
   Algoritmo eficiente para encontrar conjuntos frecuentes y generar reglas de asociaci贸n. til en an谩lisis de cestas de mercado (*market basket analysis*).

---

###  REDUCCIN DE DIMENSIONALIDAD

Aunque no est谩n en un m贸dulo espec铆fico de "unsupervised", PySpark ofrece soporte para algunos algoritmos de reducci贸n de dimensiones, 煤tiles para tareas no supervisadas:

7. **Principal Component Analysis (PCA)**
   `PCA()`
   Reducci贸n de dimensionalidad lineal, mantiene la varianza m谩xima.

8. **Truncated Singular Value Decomposition (SVD)**
   `TruncatedSVD()`
   Reducci贸n lineal de dimensiones (en Spark solo disponible para matrices dispersas como `RowMatrix` en `pyspark.mllib.linalg.distributed`).

# Partes: 2. Selecci贸n de los datos, 3. Preparaci贸n de los datos, 4. Preparaci贸n del conjunto de entrenamiento y prueba y 5. Construcci贸n de modelos de aprendizaje supervisado y no supervisado

El desarrollo de estas secciones se encuenta en el el jupyter notebook que se encuentra en este repositorio en la liga:

[Jupyter Notebook](./sesion14)
